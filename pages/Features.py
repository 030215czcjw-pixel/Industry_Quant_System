import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from filterpy.kalman import KalmanFilter

# --- é…ç½®ä¸å¸¸é‡ ---
Industry_list = ["ç…¤ç‚­", "äº¤è¿"]
SHEET_LIST = {
    "äº¤è¿": "1VVTAG1ixDe50ysjMZEAAZyvYkUbiHBvolh0oaYn8Mxw", 
    "ç…¤ç‚­": "1P3446_9mBi-7qrAMi78F1gHDHGIOCjw-"
} 

def apply_kalman(series, Q_val=0.01, R_val=0.1):
    if isinstance(series, pd.DataFrame):
        target = series.iloc[:, 0]
    else:
        target = series
    vals = target.ffill().bfill().to_numpy()
    kf = KalmanFilter(dim_x=1, dim_z=1)
    kf.x = np.array([[vals[0]]])
    kf.F = np.array([[1.]])
    kf.H = np.array([[1.]])
    kf.P *= 10.
    kf.R = R_val
    kf.Q = Q_val
    filtered_results = []
    for z in vals:
        kf.predict()
        kf.update(z)
        filtered_results.append(kf.x[0, 0])
    return pd.Series(filtered_results, index=target.index, name=getattr(target, 'name', 'filtered'))

def apply_feature_transforms(series, mode="æ— "):
    """
    æ•°å€¼å˜æ¢å¤„ç† (å•é€‰äº’æ–¥)
    - 5%ç¼©å°¾: åŸºäºåˆ†ä½æ•°
    - 3-Sigma: åŸºäºå‡å€¼æ ‡å‡†å·®
    - Log Transform: å¯¹æ•°å¤„ç† (é’ˆå¯¹ç‰¹å¾å˜æ¢åçš„æ•°æ®é‡çº§è¿›è¡Œå¤„ç†)
    - Z-score: æ ‡å‡†åŒ–
    - Robust Scaling: åŸºäºä¸­ä½æ•°å’ŒMADçš„æ ‡å‡†åŒ–
    """
    if series.empty or mode == "æ— ":
        return series
    
    s = series.copy()
    if mode == "5%ç¼©å°¾":
        s = s.clip(s.quantile(0.05), s.quantile(0.95))
    elif mode == "3-Sigmaç¼©å°¾":
        mu, sigma = s.mean(), s.std()
        s = s.clip(mu - 3 * sigma, mu + 3 * sigma)
    elif mode == "Log Transform":
        # å¯¹æ•°å˜æ¢ï¼Œå¤„ç†æ­£è´Ÿå€¼ (é’ˆå¯¹ç‰¹å¾å˜æ¢åçš„æ•°æ®é‡çº§è¿›è¡Œå¤„ç†)
        s = np.sign(s) * np.log1p(np.abs(s))
    elif mode == "Z-scoreæ ‡å‡†åŒ–":
        s = (s - s.mean()) / (s.std() + 1e-9)
    elif mode == "Robust Scaling":
        median = s.median()
        mad = (s - median).abs().median()
        # 1.4826 ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒä¸‹çš„ç¼©æ”¾å› å­
        s = (s - median) / (1.4826 * mad + 1e-9)
    return s

def generate_features(data, n_lag, n_MA, n_D, n_yoy, use_kalman, transform_method="æ— "):
    df = pd.DataFrame(index=data.index)
    df['åŸå§‹æ•°æ®'] = data.iloc[:, 0].astype('float64')
    if use_kalman:
        df['å¡å°”æ›¼æ»¤æ³¢'] = apply_kalman(df['åŸå§‹æ•°æ®'])
        base_series = df['å¡å°”æ›¼æ»¤æ³¢'] 
    else:
        base_series = df['åŸå§‹æ•°æ®']
    working_df = pd.DataFrame(index=df.index)
    has_transform = False
    if n_D > 0:
        working_df[f'å·®åˆ†{n_D}'] = base_series.diff(n_D)
        has_transform = True
    if n_yoy:
        for yoy in n_yoy:
            col_name = f'åŒæ¯”{yoy}' if yoy > 1 else 'ç¯æ¯”'
            working_df[col_name] = base_series.pct_change(yoy)
            has_transform = True
    if not has_transform:
        working_df['æ•°å€¼'] = base_series
    
    if transform_method != "æ— ":
        for col in working_df.columns:
            working_df[col] = apply_feature_transforms(working_df[col], transform_method)

    if n_lag > 0:
        for col in working_df.columns:
            working_df[col] = working_df[col].shift(n_lag)
            working_df.rename(columns={col: f"{col}_Lag{n_lag}"}, inplace=True)
    if n_MA > 0:
        for col in list(working_df.columns):
            working_df[f'{col}_MA{n_MA}'] = working_df[col].rolling(window=n_MA).mean()
    return pd.concat([df, working_df], axis=1)

def load_and_clean_feature(xl_obj, sheet_name):
    try:
        df = xl_obj.parse(sheet_name)
        for col in df.columns:
            if 'æ—¥æœŸ' in str(col) or 'Date' in str(col) or 'time' in str(col).lower():
                df[col] = pd.to_datetime(df[col])
                df.set_index(col, inplace=True)
                return df
        return df
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®å‡ºé”™: {e}")
        return pd.DataFrame()

def fetch_xl_object(sheet_id):
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx"
    return pd.ExcelFile(url)

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="ç‰¹å¾å·¥ç¨‹", layout="wide")

# --- å¸ƒå±€ç»“æ„ ---
cols = st.columns([0.5, 1, 2], vertical_alignment="top")
top_left_cell = cols[0].container(border=True, height=400)
top_right1_cell = cols[1].container(border=True, height=400)
top_right2_cell = cols[2].container(border=True, height=400)

# --- åˆå§‹åŒ– Session State ---
if 'xl_object' not in st.session_state:
    st.session_state['xl_object'] = None
if 'features' not in st.session_state:
    st.session_state['features'] = pd.DataFrame()
if 'feature_pool' not in st.session_state:
    st.session_state['feature_pool'] = pd.DataFrame()

# --- å·¦ä¸Šè§’ï¼šæ•°æ®æºåŠ è½½ ---
with top_left_cell:
    st.session_state['Industry_selected'] = st.selectbox("é€‰æ‹©è¡Œä¸š", Industry_list)
    SHEET_ID = SHEET_LIST[st.session_state['Industry_selected']]

    if st.button("åŒæ­¥äº‘ç«¯è¡¨", width='stretch'):
        with st.spinner("æ­£åœ¨ä¸‹è½½å¹¶è§£ææ•°æ®..."):
            try:
                st.session_state['xl_object'] = fetch_xl_object(SHEET_ID)
                st.success("åŒæ­¥æˆåŠŸï¼")
            except Exception as e:
                st.error(f"åŒæ­¥å¤±è´¥: {e}")

# --- å³ä¸Šè§’ï¼šé€‰æ‹©å…·ä½“ç‰¹å¾ ---
with top_right1_cell:
    xl = st.session_state['xl_object'] # è·å–å¯¹è±¡
    
    if xl is None:
        st.warning("è¯·å…ˆåœ¨å·¦ä¾§ç‚¹å‡»â€œåŒæ­¥äº‘ç«¯è¡¨â€ä»¥åŠ è½½æ•°æ®ã€‚")
        st.stop() # åœæ­¢è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œé˜²æ­¢æŠ¥é”™
    
    if st.session_state.get('feature_selected') is not None:
        default_feature = st.session_state['feature_selected']
    else:
        default_feature = None
    
    try:
        feature_selected = st.pills("é€‰æ‹©ç‰¹å¾", xl.sheet_names, selection_mode="single", default=default_feature)
        st.session_state.feature_selected = feature_selected
    except:
        feature_selected = st.pills("é€‰æ‹©ç‰¹å¾", xl.sheet_names, selection_mode="single")
        st.session_state.feature_selected = feature_selected
    
    if not feature_selected:
        st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªç‰¹å¾ã€‚")

# --- å³ä¾§ï¼šå‚æ•°æ§åˆ¶ ---
with top_right2_cell:
    st.caption("ç‰¹å¾å¤„ç†")
    
    # é‡‡ç”¨å¹¶æ’çš„äº”åˆ—å¸ƒå±€å±•ç¤ºäº”ä¸ªæ­¥éª¤
    c1, c2, c3, c3_5, c4 = st.columns([1, 1.2, 0.8, 1, 1])
    
    with c1:
        st.write("**1. æ»¤æ³¢**")
        use_kalman = st.checkbox("å¡å°”æ›¼æ»¤æ³¢", value=True, help="å¯¹åŸå§‹æ•°æ®å»å™ª")
        
    with c2:
        st.write("**2. åŒæ¯”ç¯æ¯”å·®åˆ†**")
        if 'yoy_val' not in st.session_state:
            st.session_state['yoy_val'] = 0

        st.pills("åŒç¯æ¯”å‘¨æœŸï¼ˆå¯å¤šé€‰ï¼‰", [1, 12, 52, 252], selection_mode="multi", key="yoy_pills")
        n_yoy_val = st.slider("", 0, 365, key='yoy_val')
        n_D = st.number_input("å·®åˆ†æœŸ", 0, 365, 0)
            
    with c3:
        st.write("**3. æ»å**")
        n_lag = st.slider("æ»åæœŸ", 0, 365, 0, help="ç‰¹å¾æ•´ä½“å‘åå¹³ç§»")

    with c3_5:
        st.write("**4. æ•°å€¼å˜æ¢**")
        transform_options = ["æ— ", "5%ç¼©å°¾", "3-Sigmaç¼©å°¾", "Log Transform", "Z-scoreæ ‡å‡†åŒ–", "Robust Scaling"]
        transform_method = st.selectbox(
            "é€‰æ‹©å˜æ¢", 
            options=transform_options,
            index=0,
            label_visibility="collapsed"
        )

    with c4:
        st.write("**5. ç§»åŠ¨å¹³å‡**")
        n_MA = st.number_input("MAçª—å£", 0, 365, 0, help="å¯¹å¤„ç†åçš„åºåˆ—åšå¹³æ»‘")

    # --- æŒ‰é’®åŒºåŸŸ ---
    if feature_selected:
        col_btn1, col_btn2 = st.columns(2)

        with col_btn1:
            if st.button("ğŸ“Š ç”Ÿæˆç‰¹å¾", type="primary", use_container_width=True):
                # åŠ è½½åŸå§‹æ•°æ®
                raw_df = load_and_clean_feature(xl, feature_selected)
                if not raw_df.empty:
                    # æ±‡æ€»æ‰€æœ‰åŒæ¯”ç¯æ¯”å‘¨æœŸ
                    yoy_list = []
                    if st.session_state.get('yoy_pills'):
                        yoy_list.extend(st.session_state.yoy_pills)
                    if n_yoy_val > 0 and n_yoy_val not in yoy_list:
                        yoy_list.append(n_yoy_val)

                    # è®¡ç®—ç‰¹å¾
                    st.session_state.features = generate_features(
                        raw_df, n_lag, n_MA, n_D, yoy_list, use_kalman,
                        transform_method=transform_method
                    )
                    st.success("âœ… ç‰¹å¾å·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹é¢„è§ˆ")
                else:
                    st.error("æ‰€é€‰Sheetæ•°æ®ä¸ºç©ºæˆ–æ— æ³•è§£ææ—¥æœŸã€‚")

        with col_btn2:
            if st.button("â• æ·»åŠ åˆ°ç‰¹å¾æ± ", use_container_width=True, disabled=st.session_state.features.empty):
                if not st.session_state.features.empty:
                    # ç»™åˆ—åæ·»åŠ ç‰¹å¾æºæ ‡è¯†
                    features_copy = st.session_state.features.copy()

                    # é‡å‘½åæ‰€æœ‰åˆ—ï¼ˆåŒ…æ‹¬åŸå§‹æ•°æ®å’Œå¡å°”æ›¼æ»¤æ³¢ï¼‰
                    rename_dict = {}
                    for col in features_copy.columns:
                        new_name = f"{feature_selected}_{col}"
                        rename_dict[col] = new_name

                    features_copy.rename(columns=rename_dict, inplace=True)

                    # åˆå¹¶åˆ°ç‰¹å¾æ± ï¼ˆæŒ‰æ—¥æœŸç´¢å¼•å¯¹é½ï¼‰
                    if st.session_state.feature_pool.empty:
                        st.session_state.feature_pool = features_copy
                    else:
                        # åªæ·»åŠ ä¸åœ¨ç‰¹å¾æ± ä¸­çš„åˆ—
                        new_cols = [c for c in features_copy.columns if c not in st.session_state.feature_pool.columns]
                        if new_cols:
                            st.session_state.feature_pool = pd.concat(
                                [st.session_state.feature_pool, features_copy[new_cols]],
                                axis=1
                            )
                            st.success(f"âœ… å·²æ·»åŠ  {len(new_cols)} ä¸ªç‰¹å¾åˆ°ç‰¹å¾æ± ")
                        else:
                            st.warning("âš ï¸ è¿™äº›ç‰¹å¾å·²å­˜åœ¨äºç‰¹å¾æ± ä¸­")


# --- å·¦ä¾§ï¼šç»“æœå±•ç¤º (è¡¨æ ¼ + ç»˜å›¾) ---

if not st.session_state.features.empty:
    df_res = st.session_state.features
    st.subheader(f"åˆ†æå¯¹è±¡: {st.session_state.get('feature_selected', 'æœªé€‰æ‹©')}")

    with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ®è¡¨"):
        st.dataframe(df_res, use_container_width=True)

    # --- 1. ç»˜å›¾åˆå§‹åŒ– ---
    fig = make_subplots(specs=[[{"secondary_y": True}]])

    safe_colors = [
        '#636EFA', '#00CC96', '#AB63FA', '#FFA15A', 
        '#19D3F3', '#FF6692', '#B6E880', '#FEF0D9'
    ]

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¬¬ä¸‰ä¸ªè½´ (y3)
    # å¦‚æœæœ‰â€œåŒæ¯”/ç¯æ¯”â€åˆ—ï¼Œæˆ–è€…æœ‰â€œè¶…é¢æ”¶ç›Šâ€ï¼Œéƒ½éœ€è¦å¯ç”¨ y3
    ratio_cols = [c for c in df_res.columns if 'åŒæ¯”' in c or 'ç¯æ¯”' in c]

    # æ£€æŸ¥è¶…é¢æ”¶ç›Š
    stock_chosen = st.session_state.get('stock_chosen')
    has_stock = ('stock_data' in st.session_state) and (st.session_state.stock_data is not None) and (stock_chosen is not None)
    target_col = 'ç´¯è®¡è¶…é¢æ”¶ç›Š' 
    has_excess = has_stock and (target_col in st.session_state.stock_data.columns)

    # åªè¦æœ‰æ¯”ç‡ç‰¹å¾ OR æœ‰è¶…é¢æ”¶ç›Šï¼Œå°±å¼€å¯ y3
    use_y3 = (len(ratio_cols) > 0) or has_excess

    # --- 2. ç»˜åˆ¶ç‰¹å¾çº¿ (æ™ºèƒ½åˆ†è½´) ---
    for i, col in enumerate(df_res.columns):
        line_color = safe_colors[i % len(safe_colors)]
        
       
        is_ratio = 'åŒæ¯”' in col or 'ç¯æ¯”' in col
        
        if is_ratio:
            # æŒ‚è½½åˆ° y3 (å³ä¾§ç‹¬ç«‹è½´)ï¼Œä¸å’ŒåŸå§‹æ•°æ®æŒ¤åœ¨ä¸€èµ·
            fig.add_trace(
                go.Scatter(
                    x=df_res.index, 
                    y=df_res[col], 
                    name=f"ç‰¹å¾: {col} (å³è½´2)", 
                    mode='lines',
                    line=dict(color=line_color, width=1.5),
                    yaxis="y3" # å¼ºåˆ¶æŒ‡å®šåˆ° y3
                )
            )
        else:
            # åŸå§‹æ•°æ®ã€å‡çº¿ç­‰ -> ç•™åœ¨å·¦è½´ (y1)
            fig.add_trace(
                go.Scatter(
                    x=df_res.index, 
                    y=df_res[col], 
                    name=f"ç‰¹å¾: {col} (å·¦è½´)", 
                    mode='lines',
                    line=dict(color=line_color, width=1.5) 
                ),
                secondary_y=False
            )

    # --- 3. ç»˜åˆ¶è‚¡ä»·ä¸è¶…é¢æ”¶ç›Š ---
    if has_stock:
        stock_df = st.session_state.stock_data

        # (1) ç´¯è®¡è¶…é¢æ”¶ç›Š -> æŒ‚è½½åˆ°å³è½´1 (y2)
        if has_excess:
            # ä¸ç‰¹å¾æ•°æ®ç´¢å¼•å¯¹é½ï¼Œå¹¶å¤„ç†ç¼ºå¤±å€¼
            common_index = df_res.index.intersection(stock_df.index)
            if len(common_index) > 0:
                excess_series = stock_df.loc[common_index, target_col]

                fig.add_trace(
                    go.Scatter(
                        x=common_index,
                        y=excess_series,
                        name="ç´¯è®¡è¶…é¢æ”¶ç›Š (å³è½´1)",
                        mode='lines',
                        line=dict(color='#ff7f0e', width=2),
                        connectgaps=True  # è¿æ¥ç¼ºå¤±å€¼ä¹‹é—´çš„ç‚¹
                    ),
                    secondary_y=True
                )
            else:
                st.warning("âš ï¸ è‚¡ä»·æ•°æ®ä¸ç‰¹å¾æ•°æ®çš„æ—¥æœŸæ²¡æœ‰äº¤é›†ï¼Œæ— æ³•æ˜¾ç¤ºè¶…é¢æ”¶ç›Š")
    else:
        st.warning('æç¤ºï¼šåœ¨"æ•°æ®"é¡µé¢é€‰æ‹©æ ‡çš„åï¼Œæ­¤å¤„å¯å åŠ æ˜¾ç¤ºè¶…é¢æ”¶ç›Šã€‚')

    # --- 4. å¸ƒå±€è®¾ç½® (ä¸‰è½´é€‚é…) ---
    # å¦‚æœå¯ç”¨äº† y3ï¼Œéœ€è¦ç¼©çŸ­ X è½´ç»™å³ä¾§ç•™ç©ºé—´
    domain_end = 0.88 if use_y3 else 1.0

    layout_config = dict(
        height=600,
        hovermode="x unified",
        xaxis=dict(
            domain=[0, domain_end] # æ”¶ç¼©ç»˜å›¾åŒº
        ),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
        
        # å·¦è½´ (y1)ï¼šåŸå§‹æ•°æ®
        yaxis=dict(
            title=dict(text="ç‰¹å¾æ•°å€¼", font=dict(color="#636EFA"))
        ),
        
        # å³è½´1 (y2)ï¼šç´¯è®¡è¶…é¢æ”¶ç›Š
        yaxis2=dict(
            title=dict(text="ç´¯è®¡è¶…é¢æ”¶ç›Š", font=dict(color="#ff7f0e")),
            showgrid=False,
            side="right",
            position=domain_end 
        )
    )

    # é…ç½®ç¬¬ä¸‰ä¸ªè½´ (y3)ï¼šä¸“é—¨ç”¨äº ç‰¹å¾å˜æ¢ (åŒæ¯”/ç¯æ¯”)
    if use_y3:
        layout_config['yaxis3'] = dict(
            title=dict(text="åŒæ¯”/ç¯æ¯”", font=dict(color="#00CC96")),
            anchor="free",     
            overlaying="y",    
            side="right",      
            position=0.96, # æ”¾åœ¨æœ€å³è¾¹
            showgrid=False,
            tickformat='.2%' # è‡ªåŠ¨æ ¼å¼åŒ–ä¸ºç™¾åˆ†æ¯”
        )

    fig.update_layout(**layout_config)

    # äº¤äº’ç»„ä»¶
    fig.update_xaxes(
        rangeselector=dict(
            buttons=list([
                dict(count=6, label="6æœˆ", step="month", stepmode="backward"),
                dict(count=1, label="1å¹´", step="year", stepmode="backward"),
                dict(step="all", label="å…¨éƒ¨")
            ]),
            x=0,     
            y=1.15,  
            bgcolor='rgba(255,255,255,0.8)' 
        ),
        rangeslider_visible=True
    )

    st.plotly_chart(fig, use_container_width=True)
else:
    st.info('è¯·åœ¨å³ä¾§è®¾ç½®å‚æ•°åï¼Œç‚¹å‡»"ğŸ“Š ç”Ÿæˆç‰¹å¾"æŒ‰é’®ä»¥æŸ¥çœ‹ç»“æœã€‚')

# --- ç‰¹å¾æ± ç®¡ç†åŒºåŸŸ ---
st.divider()
st.header("ğŸ—‚ï¸ ç‰¹å¾æ± ç®¡ç†", divider="rainbow")

if not st.session_state.feature_pool.empty:
    pool_df = st.session_state.feature_pool

    # ç»Ÿè®¡ä¿¡æ¯
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    col_stat1.metric("ğŸ“Š ç‰¹å¾æ•°é‡", len(pool_df.columns))
    col_stat2.metric("ğŸ“… æ•°æ®è¡Œæ•°", len(pool_df))
    col_stat3.metric("ğŸ“† èµ·å§‹æ—¥æœŸ", pool_df.index.min().strftime('%Y-%m-%d') if not pool_df.empty else 'N/A')
    col_stat4.metric("ğŸ“† ç»“æŸæ—¥æœŸ", pool_df.index.max().strftime('%Y-%m-%d') if not pool_df.empty else 'N/A')

    # æ“ä½œæŒ‰é’®
    col_op1, col_op2, col_op3 = st.columns([1, 1, 4])

    with col_op1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºç‰¹å¾æ± ", type="secondary", use_container_width=True):
            st.session_state.feature_pool = pd.DataFrame()
            st.rerun()

    with col_op2:
        # ä¸‹è½½æŒ‰é’®
        csv = pool_df.to_csv(index=True)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½CSV",
            data=csv,
            file_name=f"feature_pool_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True
        )

    # ç‰¹å¾é€‰æ‹©å’Œåˆ é™¤
    with st.expander("ğŸ”§ ç®¡ç†ç‰¹å¾åˆ—", expanded=False):
        st.caption("é€‰æ‹©è¦åˆ é™¤çš„ç‰¹å¾ï¼ˆå¯å¤šé€‰ï¼‰")

        # æŒ‰ç‰¹å¾æ¥æºåˆ†ç»„æ˜¾ç¤º
        feature_groups = {}
        for col in pool_df.columns:
            # æ‰€æœ‰ç‰¹å¾éƒ½åº”è¯¥æœ‰å‰ç¼€æ ¼å¼ï¼šç‰¹å¾å_åˆ—å
            if '_' in col:
                group = col.split('_')[0]
            else:
                group = 'å…¶ä»–'

            if group not in feature_groups:
                feature_groups[group] = []
            feature_groups[group].append(col)

        # æ˜¾ç¤ºåˆ†ç»„
        cols_to_delete = []
        for group_name, cols in feature_groups.items():
            with st.expander(f"ğŸ“ {group_name} ({len(cols)})", expanded=True):
                group_cols = st.columns(3)
                for i, col in enumerate(cols):
                    if group_cols[i % 3].checkbox(col, key=f"delete_{col}"):
                        cols_to_delete.append(col)

        if cols_to_delete:
            if st.button(f"ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­çš„ {len(cols_to_delete)} ä¸ªç‰¹å¾", type="secondary"):
                st.session_state.feature_pool.drop(columns=cols_to_delete, inplace=True)
                st.success(f"âœ… å·²åˆ é™¤ {len(cols_to_delete)} ä¸ªç‰¹å¾")
                st.rerun()

    # æ•°æ®é¢„è§ˆ
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç‰¹å¾æ± æ•°æ®", expanded=False):
        st.dataframe(
            pool_df,
            use_container_width=True,
            height=400
        )

        # æ•°æ®ç»Ÿè®¡
        st.caption("æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
        st.dataframe(
            pool_df.describe(),
            use_container_width=True
        )

else:
    st.info('ğŸ’¡ ç‰¹å¾æ± ä¸ºç©ºï¼Œè¯·å…ˆç”Ÿæˆç‰¹å¾å¹¶ç‚¹å‡»"â• æ·»åŠ åˆ°ç‰¹å¾æ± "æŒ‰é’®')