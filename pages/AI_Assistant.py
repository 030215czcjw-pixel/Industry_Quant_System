import streamlit as st
import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
from openai import OpenAI

st.set_page_config(
    page_title="AI ç­–ç•¥åŠ©æ‰‹",
    layout="wide",
    page_icon="ğŸ¤–"
)

st.title("ğŸ¤– AI ç­–ç•¥åˆ†æåŠ©æ‰‹")
st.caption("æ”¯æŒ Claudeã€DeepSeekã€æ™ºè°±ç­‰å¤šç§å¤§æ¨¡å‹")

# æ£€æµ‹æ˜¯å¦åœ¨ Streamlit Cloud è¿è¡Œ
def is_streamlit_cloud():
    """æ£€æµ‹æ˜¯å¦åœ¨ Streamlit Cloud ç¯å¢ƒè¿è¡Œ"""
    return os.getenv('STREAMLIT_SHARING_MODE') is not None or \
           os.getenv('STREAMLIT_RUNTIME_ENV') == 'cloud'

# ç”Ÿæˆå¯¹è¯å†å²çš„ JSON æ•°æ®
def generate_chat_json():
    """ç”Ÿæˆå¯ä¸‹è½½çš„å¯¹è¯å†å² JSON å­—ç¬¦ä¸²"""
    if st.session_state.ai_chat_history:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        data = {
            'timestamp': timestamp,
            'export_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'provider': st.session_state.get('current_provider', 'Unknown'),
            'model': st.session_state.get('current_model', 'Unknown'),
            'messages': st.session_state.ai_chat_history,
            'message_count': len(st.session_state.ai_chat_history)
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    return None

# ä»ä¸Šä¼ çš„ JSON åŠ è½½å¯¹è¯å†å²
def load_chat_from_json(json_str):
    """ä» JSON å­—ç¬¦ä¸²åŠ è½½å¯¹è¯å†å²"""
    try:
        data = json.loads(json_str)
        return data.get('messages', [])
    except Exception as e:
        st.error(f"åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")
        return []

# å°†DataFrameè½¬æ¢ä¸ºç»“æ„åŒ–çš„æ–‡æœ¬æè¿°
def dataframe_to_text(df, max_rows=20):
    """å°†DataFrameè½¬æ¢ä¸ºAIå¯è¯»çš„æ–‡æœ¬æ ¼å¼"""
    if df is None or df.empty:
        return "æ•°æ®ä¸ºç©º"

    text_parts = []

    # 1. åŸºæœ¬ä¿¡æ¯
    text_parts.append(f"æ•°æ®ç»´åº¦: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
    text_parts.append(f"æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
    text_parts.append(f"\nåˆ—å: {', '.join(df.columns.tolist())}")

    # 2. ç»Ÿè®¡æ‘˜è¦
    text_parts.append("\n\n=== æ•°æ®ç»Ÿè®¡æ‘˜è¦ ===")
    desc = df.describe()
    text_parts.append(desc.to_string())

    # 3. æœ€è¿‘çš„æ•°æ®æ ·æœ¬
    text_parts.append(f"\n\n=== æœ€è¿‘ {min(max_rows, len(df))} æ¡æ•°æ® ===")
    recent_data = df.tail(max_rows)
    text_parts.append(recent_data.to_string())

    # 4. å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    key_metrics = {}
    if 'ä»“ä½å‡€å€¼' in df.columns:
        key_metrics['æœ€ç»ˆç­–ç•¥å‡€å€¼'] = df['ä»“ä½å‡€å€¼'].iloc[-1]
        key_metrics['ç­–ç•¥æœ€å¤§å€¼'] = df['ä»“ä½å‡€å€¼'].max()
        key_metrics['ç­–ç•¥æœ€å°å€¼'] = df['ä»“ä½å‡€å€¼'].min()

    if 'å…ˆéªŒä»“ä½å‡€å€¼' in df.columns:
        key_metrics['æœ€ç»ˆå…ˆéªŒå‡€å€¼'] = df['å…ˆéªŒä»“ä½å‡€å€¼'].iloc[-1]

    if 'ä¹°å…¥ä¿¡å·' in df.columns:
        key_metrics['æ€»ä¹°å…¥ä¿¡å·æ¬¡æ•°'] = int(df['ä¹°å…¥ä¿¡å·'].sum())
        key_metrics['ä¿¡å·è§¦å‘ç‡'] = f"{(df['ä¹°å…¥ä¿¡å·'].sum() / len(df)):.2%}"

    if 'æŒæœ‰æœŸè¶…é¢æ”¶ç›Šç‡' in df.columns:
        wins = df[df['ä¹°å…¥ä¿¡å·'] == 1]['æŒæœ‰æœŸè¶…é¢æ”¶ç›Šç‡'] > 0
        if wins.sum() > 0:
            key_metrics['èƒœç‡'] = f"{(wins.sum() / df['ä¹°å…¥ä¿¡å·'].sum()):.2%}"

    if key_metrics:
        text_parts.append("\n\n=== å…³é”®æŒ‡æ ‡ ===")
        for key, value in key_metrics.items():
            text_parts.append(f"{key}: {value}")

    return '\n'.join(text_parts)

# åˆå§‹åŒ– session state
if 'ai_chat_history' not in st.session_state:
    st.session_state.ai_chat_history = []

# æ£€æŸ¥æ˜¯å¦æœ‰å›æµ‹ç»“æœ
has_backtest_result = 'df_backtest_result' in st.session_state and st.session_state.df_backtest_result is not None

# å¸ƒå±€
col_main, col_sidebar = st.columns([3, 1])

with col_sidebar:
    st.subheader("âš™ï¸ è®¾ç½®", divider="gray")

    # AI æä¾›å•†é€‰æ‹©
    ai_provider = st.selectbox(
        "AI æä¾›å•†",
        [
            "DeepSeek",
            "æ™ºè°± AI (GLM)",
            "é€šä¹‰åƒé—® (Qwen)",
            "Claude (Anthropic)",
            "OpenAI"
        ],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„ AI æœåŠ¡æä¾›å•†"
    )

    # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„é…ç½®
    if ai_provider == "DeepSeek":
        api_key = st.text_input(
            "DeepSeek API Key",
            type="password",
            value=os.environ.get("DEEPSEEK_API_KEY", ""),
            help="è¾“å…¥ä½ çš„ DeepSeek API Key"
        )
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["deepseek-chat", "deepseek-reasoner"],
            help="deepseek-chat: é€šç”¨å¯¹è¯æ¨¡å‹\ndeepseek-reasoner: æ¨ç†å¢å¼ºæ¨¡å‹"
        )
        base_url = "https://api.deepseek.com"

    elif ai_provider == "æ™ºè°± AI (GLM)":
        api_key = st.text_input(
            "æ™ºè°± API Key",
            type="password",
            value=os.environ.get("ZHIPU_API_KEY", ""),
            help="è¾“å…¥ä½ çš„æ™ºè°± API Key"
        )
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["glm-4-plus", "glm-4-flash", "glm-4"],
            help="glm-4-plus: æœ€å¼ºæ€§èƒ½\nglm-4-flash: å¿«é€Ÿå“åº”\nglm-4: å¹³è¡¡ç‰ˆæœ¬"
        )
        base_url = "https://open.bigmodel.cn/api/paas/v4"

    elif ai_provider == "é€šä¹‰åƒé—® (Qwen)":
        api_key = st.text_input(
            "é€šä¹‰åƒé—® API Key",
            type="password",
            value=os.environ.get("QWEN_API_KEY", ""),
            help="è¾“å…¥ä½ çš„é€šä¹‰åƒé—® API Key"
        )
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["qwen-plus", "qwen-turbo", "qwen-max"],
            help="qwen-plus: æ€§ä»·æ¯”é«˜\nqwen-turbo: å¿«é€Ÿå“åº”\nqwen-max: æœ€å¼ºæ€§èƒ½"
        )
        base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"

    elif ai_provider == "Claude (Anthropic)":
        api_key = st.text_input(
            "Anthropic API Key",
            type="password",
            value=os.environ.get("ANTHROPIC_API_KEY", ""),
            help="è¾“å…¥ä½ çš„ Anthropic API Key"
        )
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229", "claude-3-haiku-20240307"],
            help="Sonnet: å¹³è¡¡æ€§èƒ½\nOpus: æœ€å¼ºæ€§èƒ½\nHaiku: æœ€å¿«é€Ÿåº¦"
        )
        base_url = None  # Anthropic ä½¿ç”¨å®˜æ–¹ SDK

    else:  # OpenAI
        api_key = st.text_input(
            "OpenAI API Key",
            type="password",
            value=os.environ.get("OPENAI_API_KEY", ""),
            help="è¾“å…¥ä½ çš„ OpenAI API Key"
        )
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
            help="gpt-4o: æœ€æ–°æ¨¡å‹\ngpt-4-turbo: å¿«é€Ÿç‰ˆGPT-4\ngpt-3.5-turbo: ç»æµå®æƒ "
        )
        base_url = "https://api.openai.com/v1"

    # æ¸©åº¦å‚æ•°
    temperature = st.slider(
        "åˆ›é€ æ€§",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="æ•°å€¼è¶Šé«˜ï¼Œå›ç­”è¶Šæœ‰åˆ›é€ æ€§"
    )

    st.divider()

    # ä¿å­˜å½“å‰æä¾›å•†å’Œæ¨¡å‹
    st.session_state.current_provider = ai_provider
    st.session_state.current_model = model_choice

    # æ“ä½œæŒ‰é’®
    col_btn1, col_btn2 = st.columns(2)

    with col_btn1:
        # ä¸‹è½½å¯¹è¯æŒ‰é’®
        chat_json = generate_chat_json()
        if chat_json:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="ğŸ’¾ ä¸‹è½½å¯¹è¯",
                data=chat_json,
                file_name=f"chat_{timestamp}.json",
                mime="application/json",
                use_container_width=True,
                help="å°†å½“å‰å¯¹è¯ä¸‹è½½åˆ°æœ¬åœ°"
            )
        else:
            st.button("ğŸ’¾ ä¸‹è½½å¯¹è¯", disabled=True, use_container_width=True, help="æš‚æ— å¯¹è¯å¯ä¸‹è½½")

    with col_btn2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.ai_chat_history = []
            st.rerun()

    # ä¸Šä¼ å¹¶åŠ è½½å†å²å¯¹è¯
    with st.expander("ğŸ“‚ ä¸Šä¼ å†å²å¯¹è¯", expanded=False):
        uploaded_file = st.file_uploader(
            "é€‰æ‹©å¯¹è¯æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰",
            type=['json'],
            help="ä¸Šä¼ ä¹‹å‰ä¸‹è½½çš„å¯¹è¯è®°å½•",
            label_visibility="collapsed"
        )

        if uploaded_file is not None:
            try:
                # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
                json_str = uploaded_file.read().decode('utf-8')

                # æ˜¾ç¤ºé¢„è§ˆä¿¡æ¯
                preview_data = json.loads(json_str)
                st.info(f"""
                **ğŸ“‹ å¯¹è¯é¢„è§ˆ**
                - å¯¼å‡ºæ—¶é—´: {preview_data.get('export_time', 'æœªçŸ¥')}
                - AIæä¾›å•†: {preview_data.get('provider', 'æœªçŸ¥')}
                - æ¨¡å‹: {preview_data.get('model', 'æœªçŸ¥')}
                - æ¶ˆæ¯æ•°é‡: {preview_data.get('message_count', 0)} æ¡
                """)

                if st.button("ğŸ“¥ åŠ è½½æ­¤å¯¹è¯", use_container_width=True, type="primary"):
                    loaded_history = load_chat_from_json(json_str)
                    if loaded_history:
                        st.session_state.ai_chat_history = loaded_history
                        st.success(f"âœ… å·²åŠ è½½ {len(loaded_history)} æ¡å¯¹è¯")
                        st.rerun()
                    else:
                        st.error("âŒ å¯¹è¯æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è§£æå¤±è´¥: {e}")

    if st.button("ğŸ“‹ æŸ¥çœ‹ç³»ç»Ÿä¿¡æ¯", use_container_width=True):
        st.session_state.show_system_info = not st.session_state.get('show_system_info', False)

    st.divider()

    # å›æµ‹æ•°æ®çŠ¶æ€
    st.subheader("ğŸ“Š æ•°æ®çŠ¶æ€")
    if has_backtest_result:
        df_res = st.session_state.df_backtest_result
        st.success("âœ… å›æµ‹æ•°æ®å·²åŠ è½½")
        st.metric("æ•°æ®è¡Œæ•°", len(df_res))
        st.metric("èµ·å§‹æ—¥æœŸ", df_res.index.min().strftime('%Y-%m-%d'))
        st.metric("ç»“æŸæ—¥æœŸ", df_res.index.max().strftime('%Y-%m-%d'))
    else:
        st.warning("âš ï¸ æš‚æ— å›æµ‹æ•°æ®")
        st.info("è¯·å…ˆåœ¨ Backtest é¡µé¢è¿è¡Œå›æµ‹")

with col_main:
    if not api_key:
        st.warning(f"âš ï¸ è¯·åœ¨å³ä¾§è¾“å…¥ {ai_provider} API Key ä»¥ä½¿ç”¨ AI åŠ©æ‰‹")

        # æ˜¾ç¤ºè·å–æ–¹æ³•
        if ai_provider == "DeepSeek":
            st.info("""
            ### å¦‚ä½•è·å– DeepSeek API Keyï¼Ÿ
            1. è®¿é—® [DeepSeek å¼€æ”¾å¹³å°](https://platform.deepseek.com/)
            2. æ³¨å†Œ/ç™»å½•è´¦å·
            3. åœ¨ API Keys é¡µé¢åˆ›å»ºæ–°çš„ API Key
            4. å°† Key ç²˜è´´åˆ°å³ä¾§è¾“å…¥æ¡†

            **ä¼˜åŠ¿**: ä»·æ ¼æä½ï¼Œæ¨ç†èƒ½åŠ›å¼ºï¼Œé€‚åˆä¸­æ–‡åœºæ™¯
            """)
        elif ai_provider == "æ™ºè°± AI (GLM)":
            st.info("""
            ### å¦‚ä½•è·å–æ™ºè°± API Keyï¼Ÿ
            1. è®¿é—® [æ™ºè°± AI å¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
            2. æ³¨å†Œ/ç™»å½•è´¦å·
            3. åœ¨ API Keys é¡µé¢åˆ›å»ºæ–°çš„ API Key
            4. å°† Key ç²˜è´´åˆ°å³ä¾§è¾“å…¥æ¡†

            **ä¼˜åŠ¿**: å›½äº§æ¨¡å‹ï¼Œä¸­æ–‡ç†è§£å¥½ï¼Œæ€§ä»·æ¯”é«˜
            """)
        elif ai_provider == "é€šä¹‰åƒé—® (Qwen)":
            st.info("""
            ### å¦‚ä½•è·å–é€šä¹‰åƒé—® API Keyï¼Ÿ
            1. è®¿é—® [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://dashscope.aliyun.com/)
            2. æ³¨å†Œ/ç™»å½•è´¦å·
            3. åœ¨ API Key ç®¡ç†é¡µé¢åˆ›å»ºæ–°çš„ Key
            4. å°† Key ç²˜è´´åˆ°å³ä¾§è¾“å…¥æ¡†

            **ä¼˜åŠ¿**: é˜¿é‡Œå·´å·´å‡ºå“ï¼Œç¨³å®šå¯é ï¼Œå¤šè¯­è¨€æ”¯æŒ
            """)
        elif ai_provider == "Claude (Anthropic)":
            st.info("""
            ### å¦‚ä½•è·å– Anthropic API Keyï¼Ÿ
            1. è®¿é—® [Anthropic Console](https://console.anthropic.com/)
            2. æ³¨å†Œ/ç™»å½•è´¦å·
            3. åˆ›å»º API Key
            4. å°† Key ç²˜è´´åˆ°å³ä¾§è¾“å…¥æ¡†

            **ä¼˜åŠ¿**: æ¨ç†èƒ½åŠ›å¼ºï¼Œå®‰å…¨æ€§é«˜ï¼Œè¾“å‡ºè´¨é‡å¥½
            """)
        else:  # OpenAI
            st.info("""
            ### å¦‚ä½•è·å– OpenAI API Keyï¼Ÿ
            1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
            2. æ³¨å†Œ/ç™»å½•è´¦å·
            3. åœ¨ API Keys é¡µé¢åˆ›å»ºæ–°çš„ Key
            4. å°† Key ç²˜è´´åˆ°å³ä¾§è¾“å…¥æ¡†

            **ä¼˜åŠ¿**: æœ€å¼ºå¤§çš„é€šç”¨æ¨¡å‹ï¼Œå¤šæ¨¡æ€èƒ½åŠ›
            """)
    else:
        # å‡†å¤‡ç³»ç»Ÿæç¤ºè¯
        if has_backtest_result:
            df_res = st.session_state.df_backtest_result

            # è®¡ç®—å…³é”®æŒ‡æ ‡
            final_nav = df_res['ä»“ä½å‡€å€¼'].iloc[-1]
            prior_nav = df_res['å…ˆéªŒä»“ä½å‡€å€¼'].iloc[-1]
            excess_gain = final_nav - prior_nav

            context_data = {
                "ç­–ç•¥å‡€å€¼": final_nav,
                "å…ˆéªŒå‡€å€¼": prior_nav,
                "è¶…é¢å¢ç›Š": excess_gain,
                "æ•°æ®è¡Œæ•°": len(df_res),
                "èµ·å§‹æ—¥æœŸ": df_res.index.min().strftime('%Y-%m-%d'),
                "ç»“æŸæ—¥æœŸ": df_res.index.max().strftime('%Y-%m-%d'),
                "ä¹°å…¥ä¿¡å·æ¬¡æ•°": int(df_res['ä¹°å…¥ä¿¡å·'].sum()),
                "ä¿¡å·è§¦å‘æ¬¡æ•°": int(df_res['ä¿¡å·è§¦å‘'].sum()),
                "æ ‡çš„": st.session_state.get('stock_chosen', 'æœªçŸ¥'),
                "åŸºå‡†": st.session_state.get('base_chosen', 'æœªçŸ¥'),
                "æŒæœ‰æœŸ": st.session_state.get('holding_period', 'æœªçŸ¥'),
                "è§‚å¯ŸæœŸ": st.session_state.get('observation_period', 'æœªçŸ¥'),
                "ç›®æ ‡è¶…é¢æ”¶ç›Š": st.session_state.get('profit_target', 'æœªçŸ¥'),
            }

            # è®¡ç®—æ›´å¤šç»Ÿè®¡æŒ‡æ ‡
            stats_data = {
                "æœ€ç»ˆç­–ç•¥å‡€å€¼": f"{final_nav:.4f}",
                "æœ€ç»ˆå…ˆéªŒå‡€å€¼": f"{prior_nav:.4f}",
                "æ€»æ”¶ç›Šç‡": f"{(final_nav - 1):.2%}",
                "å¹´åŒ–æ”¶ç›Šç‡": f"{((final_nav ** (252 / len(df_res))) - 1):.2%}" if len(df_res) > 0 else "N/A",
                "æœ€å¤§å›æ’¤": f"{(df_res['ä»“ä½å‡€å€¼'] / df_res['ä»“ä½å‡€å€¼'].cummax() - 1).min():.2%}",
                "èƒœç‡": f"{(df_res[df_res['ä¹°å…¥ä¿¡å·'] == 1]['æŒæœ‰æœŸè¶…é¢æ”¶ç›Šç‡'] > 0).sum() / max(df_res['ä¹°å…¥ä¿¡å·'].sum(), 1):.2%}",
            }

            # å°†DataFrameè½¬æ¢ä¸ºæ–‡æœ¬
            df_text = dataframe_to_text(df_res, max_rows=30)

            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–ç­–ç•¥åˆ†æåŠ©æ‰‹ã€‚ä½ æ­£åœ¨å¸®åŠ©ç”¨æˆ·åˆ†æä¸€ä¸ªåŸºäºè´å¶æ–¯æ›´æ–°çš„æ‹©æ—¶ç­–ç•¥å›æµ‹ç»“æœã€‚

å›æµ‹é…ç½®ï¼š
- æ ‡çš„ï¼š{context_data['æ ‡çš„']}
- åŸºå‡†ï¼š{context_data['åŸºå‡†']}
- å›æµ‹å‘¨æœŸï¼š{context_data['èµ·å§‹æ—¥æœŸ']} è‡³ {context_data['ç»“æŸæ—¥æœŸ']}
- æŒæœ‰æœŸï¼š{context_data['æŒæœ‰æœŸ']} å¤©
- è§‚å¯ŸæœŸï¼š{context_data['è§‚å¯ŸæœŸ']} å¤©
- ç›®æ ‡è¶…é¢æ”¶ç›Šï¼š{context_data['ç›®æ ‡è¶…é¢æ”¶ç›Š']}

å…³é”®æŒ‡æ ‡ï¼š
- ç­–ç•¥å‡€å€¼ï¼š{stats_data['æœ€ç»ˆç­–ç•¥å‡€å€¼']} ({stats_data['æ€»æ”¶ç›Šç‡']})
- å…ˆéªŒå‡€å€¼ï¼š{stats_data['æœ€ç»ˆå…ˆéªŒå‡€å€¼']}
- è¶…é¢å¢ç›Šï¼š{context_data['è¶…é¢å¢ç›Š']:.4f}
- å¹´åŒ–æ”¶ç›Šç‡ï¼š{stats_data['å¹´åŒ–æ”¶ç›Šç‡']}
- æœ€å¤§å›æ’¤ï¼š{stats_data['æœ€å¤§å›æ’¤']}
- èƒœç‡ï¼š{stats_data['èƒœç‡']}
- ä¹°å…¥ä¿¡å·æ¬¡æ•°ï¼š{context_data['ä¹°å…¥ä¿¡å·æ¬¡æ•°']}
- ä¿¡å·è§¦å‘æ¬¡æ•°ï¼š{context_data['ä¿¡å·è§¦å‘æ¬¡æ•°']}

=== å®Œæ•´å›æµ‹æ•°æ® ===
ä»¥ä¸‹æ˜¯è¯¦ç»†çš„å›æµ‹æ•°æ®ï¼Œä½ å¯ä»¥åŸºäºè¿™äº›æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æï¼š

{df_text}

ä½ å¯ä»¥æ ¹æ®ä»¥ä¸Šå®Œæ•´çš„æ•°æ®ï¼š
1. è§£è¯»å›æµ‹æŒ‡æ ‡çš„å«ä¹‰å’Œå…·ä½“æ•°å€¼
2. åˆ†æç­–ç•¥åœ¨ä¸åŒæ—¶é—´æ®µçš„è¡¨ç°
3. è¯†åˆ«ç­–ç•¥çš„ä¼˜ç¼ºç‚¹å’Œé£é™©ç‚¹
4. åŸºäºæ•°æ®æä¾›ä¼˜åŒ–å»ºè®®
5. å›ç­”å…³äºè´å¶æ–¯æ›´æ–°æœºåˆ¶çš„é—®é¢˜
6. è§£é‡Šå…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡çš„ä½œç”¨
7. åˆ†æä¿¡å·è§¦å‘çš„æ—¶æœºå’Œè´¨é‡
8. è¯„ä¼°ç­–ç•¥çš„ç¨³å®šæ€§å’Œå¯é æ€§

è¯·ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”ï¼Œå¿…é¡»ä½¿ç”¨å…·ä½“æ•°æ®æ”¯æ’‘ä½ çš„è§‚ç‚¹ã€‚"""
        else:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–ç­–ç•¥åˆ†æåŠ©æ‰‹ã€‚è™½ç„¶å½“å‰æ²¡æœ‰åŠ è½½å›æµ‹æ•°æ®ï¼Œä½†ä½ å¯ä»¥ï¼š
1. å›ç­”å…³äºé‡åŒ–ç­–ç•¥çš„ä¸€èˆ¬é—®é¢˜
2. è§£é‡Šè´å¶æ–¯æ›´æ–°ã€æ‹©æ—¶ç­–ç•¥ç­‰æ¦‚å¿µ
3. æä¾›ç­–ç•¥è®¾è®¡å’Œä¼˜åŒ–çš„å»ºè®®
4. è®¨è®ºé£é™©ç®¡ç†å’Œèµ„é‡‘ç®¡ç†
5. è§£ç­”å…³äºå›æµ‹æ–¹æ³•è®ºçš„é—®é¢˜

è¯·ç”¨ä¸“ä¸šã€æ˜“æ‡‚çš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if st.session_state.get('show_system_info', False):
            with st.expander("ğŸ“‹ ç³»ç»Ÿæç¤ºè¯", expanded=True):
                st.code(system_prompt, language="text")

        # æ˜¾ç¤ºå¯¹è¯å†å²
        for message in st.session_state.ai_chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # ç”¨æˆ·è¾“å…¥
        if has_backtest_result:
            placeholder_text = "é—®æˆ‘ä»»ä½•å…³äºè¿™ä¸ªå›æµ‹çš„é—®é¢˜..."
        else:
            placeholder_text = "é—®æˆ‘å…³äºé‡åŒ–ç­–ç•¥çš„é—®é¢˜..."

        user_question = st.chat_input(placeholder_text)

        if user_question:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            st.session_state.ai_chat_history.append({
                "role": "user",
                "content": user_question
            })

            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(user_question)

            # è°ƒç”¨ AI API
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""

                try:
                    # ä½¿ç”¨ OpenAI å…¼å®¹çš„ APIï¼ˆé€‚ç”¨äº DeepSeekã€æ™ºè°±ã€é€šä¹‰ç­‰ï¼‰
                    if ai_provider != "Claude (Anthropic)":
                        client = OpenAI(
                            api_key=api_key,
                            base_url=base_url
                        )

                        # æ„å»ºæ¶ˆæ¯å†å²
                        messages = [{"role": "system", "content": system_prompt}]
                        for msg in st.session_state.ai_chat_history:
                            messages.append({
                                "role": msg["role"],
                                "content": msg["content"]
                            })

                        # æµå¼è°ƒç”¨
                        stream = client.chat.completions.create(
                            model=model_choice,
                            messages=messages,
                            temperature=temperature,
                            stream=True
                        )

                        for chunk in stream:
                            if chunk.choices[0].delta.content is not None:
                                full_response += chunk.choices[0].delta.content
                                message_placeholder.markdown(full_response + "â–Œ")

                    else:  # Claude ä½¿ç”¨å®˜æ–¹ SDK
                        import anthropic
                        client = anthropic.Anthropic(api_key=api_key)

                        # æ„å»ºæ¶ˆæ¯å†å²
                        messages = []
                        for msg in st.session_state.ai_chat_history:
                            messages.append({
                                "role": msg["role"],
                                "content": msg["content"]
                            })

                        # æµå¼è°ƒç”¨
                        with client.messages.stream(
                            model=model_choice,
                            max_tokens=2048,
                            temperature=temperature,
                            system=system_prompt,
                            messages=messages,
                        ) as stream:
                            for text in stream.text_stream:
                                full_response += text
                                message_placeholder.markdown(full_response + "â–Œ")

                    message_placeholder.markdown(full_response)

                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                    st.session_state.ai_chat_history.append({
                        "role": "assistant",
                        "content": full_response
                    })
                    # é‡æ–°è¿è¡Œè„šæœ¬ï¼Œç¡®ä¿ä¸‹è½½æŒ‰é’®å’Œå…¶ä»–ç»„ä»¶æ›´æ–°
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ API è°ƒç”¨å¤±è´¥: {str(e)}")
                    st.info(f"""
                    è¯·æ£€æŸ¥ï¼š
                    1. {ai_provider} API Key æ˜¯å¦æ­£ç¡®
                    2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
                    3. API é…é¢æ˜¯å¦å……è¶³
                    4. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®

                    é”™è¯¯è¯¦æƒ…: {type(e).__name__}
                    """)

# é¡µé¢åº•éƒ¨è¯´æ˜
st.divider()
with st.expander("ğŸ’¡ ä½¿ç”¨æç¤º", expanded=False):
    st.markdown("""
    ### ç¤ºä¾‹é—®é¢˜

    **å…³äºå›æµ‹ç»“æœï¼š**
    - "å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªç­–ç•¥çš„è¡¨ç°å¦‚ä½•ï¼Ÿ"
    - "ä¸ºä»€ä¹ˆç­–ç•¥å‡€å€¼æ¯”å…ˆéªŒå‡€å€¼é«˜/ä½ï¼Ÿ"
    - "è¿™ä¸ªç­–ç•¥çš„æœ€å¤§å›æ’¤è¯´æ˜äº†ä»€ä¹ˆï¼Ÿ"
    - "èƒœç‡è¿™ä¸ªæŒ‡æ ‡å¦‚ä½•è§£è¯»ï¼Ÿ"

    **å…³äºç­–ç•¥ä¼˜åŒ–ï¼š**
    - "å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªç­–ç•¥ï¼Ÿ"
    - "åº”è¯¥è°ƒæ•´å“ªäº›å‚æ•°ï¼Ÿ"
    - "æŒæœ‰æœŸå’Œè§‚å¯ŸæœŸå¦‚ä½•è®¾ç½®æ¯”è¾ƒåˆç†ï¼Ÿ"

    **å…³äºè´å¶æ–¯æœºåˆ¶ï¼š**
    - "è´å¶æ–¯æ›´æ–°åœ¨è¿™ä¸ªç­–ç•¥ä¸­æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
    - "å…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
    - "ä¸ºä»€ä¹ˆè¦ä½¿ç”¨è´å¶æ–¯æ–¹æ³•ï¼Ÿ"

    **å…³äºé£é™©ç®¡ç†ï¼š**
    - "è¿™ä¸ªç­–ç•¥çš„é£é™©ç‚¹åœ¨å“ªé‡Œï¼Ÿ"
    - "å¦‚ä½•æ§åˆ¶å›æ’¤ï¼Ÿ"
    - "ä»“ä½ç®¡ç†æœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ"

    **å…³äºæ•°æ®åˆ†æï¼š**
    - "å¸®æˆ‘åˆ†ææœ€è¿‘30å¤©çš„äº¤æ˜“ä¿¡å·è´¨é‡"
    - "å“ªäº›æ—¶é—´æ®µç­–ç•¥è¡¨ç°æœ€å¥½/æœ€å·®ï¼Ÿ"
    - "ä¿¡å·è§¦å‘ç‡æ˜¯å¦åˆç†ï¼Ÿ"
    - "åéªŒæ¦‚ç‡ç›¸æ¯”å…ˆéªŒæ¦‚ç‡æå‡äº†å¤šå°‘ï¼Ÿ"

    ### æ¨¡å‹æ¨è

    - **DeepSeek**: ä»·æ ¼æœ€ä½ï¼Œæ¨ç†èƒ½åŠ›å¼ºï¼Œé€‚åˆé«˜é¢‘ä½¿ç”¨
    - **æ™ºè°± GLM**: ä¸­æ–‡ç†è§£å¥½ï¼Œå“åº”å¿«ï¼Œæ€§ä»·æ¯”é«˜
    - **é€šä¹‰åƒé—®**: é˜¿é‡Œå·´å·´å‡ºå“ï¼Œç¨³å®šå¯é 
    - **Claude**: æ¨ç†èƒ½åŠ›æœ€å¼ºï¼Œè¾“å‡ºè´¨é‡æœ€é«˜
    - **OpenAI GPT-4**: æœ€å…¨é¢çš„èƒ½åŠ›ï¼Œå¤šæ¨¡æ€æ”¯æŒ

    ### ğŸ’¾ å†å²å¯¹è¯ç®¡ç†

    **ä¸‹è½½å¯¹è¯:**
    1. ä¸AIå¯¹è¯åï¼Œç‚¹å‡»ä¾§è¾¹æ "ğŸ’¾ ä¸‹è½½å¯¹è¯"æŒ‰é’®
    2. æµè§ˆå™¨ä¼šè‡ªåŠ¨ä¸‹è½½ `chat_YYYYMMDD_HHMMSS.json` æ–‡ä»¶
    3. æ–‡ä»¶åŒ…å«ï¼šå¯¼å‡ºæ—¶é—´ã€AIæä¾›å•†ã€æ¨¡å‹ã€å®Œæ•´å¯¹è¯è®°å½•

    **ä¸Šä¼ å¯¹è¯:**
    1. å±•å¼€"ğŸ“‚ ä¸Šä¼ å†å²å¯¹è¯"é¢æ¿
    2. ç‚¹å‡»"Browse files"é€‰æ‹©ä¹‹å‰ä¸‹è½½çš„ JSON æ–‡ä»¶
    3. æŸ¥çœ‹å¯¹è¯é¢„è§ˆä¿¡æ¯ï¼ˆæ—¶é—´ã€æä¾›å•†ã€æ¶ˆæ¯æ•°é‡ï¼‰
    4. ç‚¹å‡»"ğŸ“¥ åŠ è½½æ­¤å¯¹è¯"æŒ‰é’®æ¢å¤å¯¹è¯
    5. å¯ç»§ç»­ä¸AIäº¤æµï¼Œæ— ç¼è¡”æ¥

    **é€‚ç”¨åœºæ™¯:**
    - âœ… æœ¬åœ°è¿è¡Œ Streamlit
    - âœ… Streamlit Cloud éƒ¨ç½²
    - âœ… è·¨è®¾å¤‡ä½¿ç”¨ï¼ˆä¸‹è½½åä¼ è¾“åˆ°å…¶ä»–è®¾å¤‡ï¼‰
    - âœ… å¤‡ä»½é‡è¦å¯¹è¯

    ### ğŸ“Š æ•°æ®è®¿é—®èƒ½åŠ›

    AIåŠ©æ‰‹ç°åœ¨å¯ä»¥è®¿é—®å®Œæ•´çš„å›æµ‹DataFrameï¼ŒåŒ…æ‹¬ï¼š
    - æ‰€æœ‰åˆ—çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€åˆ†ä½æ•°ç­‰ï¼‰
    - æœ€è¿‘30æ¡è¯¦ç»†æ•°æ®è®°å½•
    - å…³é”®æŒ‡æ ‡çš„è‡ªåŠ¨è®¡ç®—
    - æ—¶é—´åºåˆ—æ•°æ®çš„å®Œæ•´ä¿¡æ¯

    è¿™æ„å‘³ç€AIå¯ä»¥ï¼š
    - æ·±å…¥åˆ†æå…·ä½“çš„äº¤æ˜“ä¿¡å·
    - è¯†åˆ«ç‰¹å®šæ—¶é—´æ®µçš„è¡¨ç°
    - æä¾›åŸºäºå®é™…æ•°æ®çš„ä¼˜åŒ–å»ºè®®
    - å›ç­”å…³äºæ•°æ®ç»†èŠ‚çš„é—®é¢˜
    """)
